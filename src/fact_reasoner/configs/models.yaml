RITS_MODELS:
  deepseek-v3":
    model_id: "openai/deepseek-ai/DeepSeek-V3"
    api_base: "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/deepseek-v3/v1"
    max_new_tokens: 4096
    prompt_template: "<|begin_of_text|><|begin▁of▁sentence|>user<|end▁of▁sentence|>\n\n{}<|end|><|begin▁of▁sentence|>assistant<|end▁of▁sentence|>"
    prompt_begin: "<|begin_of_text|><|begin▁of▁sentence|>user<|end▁of▁sentence|>"
    prompt_end: "<|end|><|begin▁of▁sentence|>assistant<|end▁of▁sentence|>"
  granite-3.2-8b-instruct:
    model_id: "openai/ibm-granite/granite-3.2-8b-instruct"
    api_base: "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/granite-3-2-8b-instruct/v1"
    max_new_tokens: 128000
    prompt_template: "<|start_of_role|>user<|end_of_role|>{}<|end_of_text|>\n<|start_of_role|>assistant<|end_of_role|>"
    prompt_begin: "<|start_of_role|>user<|end_of_role|>"
    prompt_end: "<|end_of_text|>\n<|start_of_role|>assistant<|end_of_role|>"
  granite-3.3-8b-instruct:
    model_id: "openai/ibm-granite/granite-3.3-8b-instruct"
    api_base: "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/granite-3-3-8b-instruct/v1"
    max_new_tokens: 128000
    prompt_template: "<|start_of_role|>user<|end_of_role|>{}<|end_of_text|>\n<|start_of_role|>assistant<|end_of_role|>"
    prompt_begin: "<|start_of_role|>user<|end_of_role|>"
    prompt_end: "<|end_of_text|>\n<|start_of_role|>assistant<|end_of_role|>"
  llama-3.3-70b-instruct:
    model_id: "openai/meta-llama/llama-3-3-70b-instruct"
    api_base: "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-3-3-70b-instruct/v1"
    max_new_tokens: 128000
    prompt_template: "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
    prompt_begin: "<|begin_of_text|><|start_header_id|>user<|end_header_id|>"
    prompt_end: "<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
  llama-4-maverick-17b-128e-instruct-fp8":
    model_id: "openai/meta-llama/llama-4-maverick-17b-128e-instruct-fp8"
    api_base: "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-4-mvk-17b-128e-fp8/v1"
    max_new_tokens: 128000
    prompt_template: "<|begin_of_text|><|header_start|>user<|header_end|>\n\n{}<|eot|><|header_start|>assistant<|header_end|>"
    prompt_begin: "<|begin_of_text|><|header_start|>user<|header_end|>"
    prompt_end: "<|eot|><|header_start|>assistant<|header_end|>"
  llama-4-scout-17b-16e:
    model_id: "openai/meta-llama/llama-4-scout-17b-16e"
    api_base: "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/llama-4-scout-17b-16e/v1"
    max_new_tokens: 128000
    prompt_template: "<|begin_of_text|><|header_start|>user<|header_end|>\n\n{}<|eot|><|header_start|>assistant<|header_end|>"
    prompt_begin: "<|begin_of_text|><|header_start|>user<|header_end|>"
    prompt_end: "<|eot|><|header_start|>assistant<|header_end|>"
  mixtral-8x7b-instruct:
    model_id: "openai/mistralai/mixtral-8x7B-instruct-v0.1"
    api_base: "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral-8x7b-instruct-v01/v1"
    max_new_tokens: 16384
    prompt_template: "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
    prompt_begin: "<|begin_of_text|><|start_header_id|>user<|end_header_id|>"
    prompt_end: "<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
  mixtral-8x22b-instruct:
    model_id: "openai/mistralai/mixtral-8x22B-instruct-v0.1"
    api_base: "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/mixtral-8x22b-instruct-v01/v1"
    max_new_tokens: 16384
    prompt_template: "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
    prompt_begin: "<|begin_of_text|><|start_header_id|>user<|end_header_id|>"
    prompt_end: "<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
  phi-4:
    model_id: "openai/microsoft/phi-4"
    api_base: "https://inference-3scale-apicast-production.apps.rits.fmaas.res.ibm.com/microsoft-phi-4/v1"
    max_new_tokens": 8196
    prompt_template": "<|begin_of_text|><|im_start|>user<|im_end|>\n\n{}<|end|><|im_start|>assistant<|im_end|>"
    prompt_begin": "<|begin_of_text|><|im_start|>user<|im_end|>"
    prompt_end": "<|end|><|im_start|>assistant<|im_end|>"
HF_MODELS:
  mixtral-8x22b-instruct:
    model_id: "mistralai/Mixtral-8x22B-Instruct-v0.1"
    max_new_tokens: 16384
    prompt_template: "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
    prompt_begin: "<|begin_of_text|><|start_header_id|>user<|end_header_id|>"
    prompt_end: "<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
  mixtral-8x7b-instruct:
    model_id: "mistralai/mixtral-8x7B-instruct-v0.1"
    max_new_tokens: 16384
    prompt_template: "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
    prompt_begin: "<|begin_of_text|><|start_header_id|>user<|end_header_id|>"
    prompt_end: "<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
  facebook/opt-350m:
    model_id: "facebook/opt-350m"
    max_new_tokens: 16384
    prompt_template: "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
    prompt_begin: "<|begin_of_text|><|start_header_id|>user<|end_header_id|>"
    prompt_end: "<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
WX_MODELS:
  mixtral-8x22b-instruct:
    model_id: "watsonx/mistralai/Mixtral-8x22B-Instruct-v0.1"
    api_base: ""
    max_new_tokens: 16384
    prompt_template: "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
    prompt_begin: "<|begin_of_text|><|start_header_id|>user<|end_header_id|>"
    prompt_end: "<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
  llama-3.3-70b-instruct:
    model_id: "watsonx/meta-llama/llama-3-3-70b-instruct"
    api_base: ""
    max_new_tokens: 128000
    prompt_template: "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n\n{}<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
    prompt_begin: "<|begin_of_text|><|start_header_id|>user<|end_header_id|>"
    prompt_end: "<|eot_id|><|start_header_id|>assistant<|end_header_id|>"
